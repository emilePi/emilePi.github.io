[{"authors":["admin"],"categories":null,"content":"I recently completed my PhD on \u0026ldquo;Stochastic Super-resolution and Inverse Problems: From Gaussian Conditional Sampling to Diffusion Models\u0026rdquo; under the supervision of Bruno Galerne (defended on July 10, 2025).\nIn this work, I studied sampling for inverse problems, with a particular focus on stochastic super-resolution within the mathematical framework of Gaussian image distributions and using diffusion models.\nThe manuscript will be available online soon, but some of the results are presented in the Featured Publications section.\nI’m happy to be starting a postdoctoral position in September with Julie Delon.\nFeel free to contact me about anything.\n","date":1746057600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1746057600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://localhost:1313/author/emile-pierret/","publishdate":"2025-05-01T00:00:00Z","relpermalink":"/author/emile-pierret/","section":"authors","summary":"I recently completed my PhD on \u0026ldquo;Stochastic Super-resolution and Inverse Problems: From Gaussian Conditional Sampling to Diffusion Models\u0026rdquo; under the supervision of Bruno Galerne (defended on July 10, 2025).\nIn this work, I studied sampling for inverse problems, with a particular focus on stochastic super-resolution within the mathematical framework of Gaussian image distributions and using diffusion models.","tags":null,"title":"Emile Pierret","type":"authors"},{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a953903e9e986686a8773fc7f36bd2d6","permalink":"http://localhost:1313/author/emile-pierret/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/emile-pierret/","section":"authors","summary":"","tags":null,"title":"Emile Pierret","type":"authors"},{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4036ab9376e924db20b9e42fb1307811","permalink":"http://localhost:1313/author/emile-pierret/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/emile-pierret/","section":"authors","summary":"","tags":null,"title":"Emile Pierret","type":"authors"},{"authors":["Emile Pierret","Bruno Galerne"],"categories":[],"content":"Background We keep the same equation numbering as in the paper.\nWe study the continuous formulation of diffusion models, focusing on the Variance Preserving (VP-SDE) framework [Song et al., 2021]. The forward process is:\n\\begin{equation} \\label{eq:sde_forward} d\\boldsymbol{x}_t =- \\beta_t \\boldsymbol{x}_t dt + \\sqrt{2\\beta_t}d\\boldsymbol{w}_t, \\quad 0 \\leq t \\leq T, \\boldsymbol{x}_0 \\sim p_{\\text{data}}. \\tag{1} \\end{equation}\nThis degrades the data progressively. Denoting by $p_t$ the marginal distribution of $ \\boldsymbol{x}_t$, we have $p_T$ close to $\\mathcal{N}(0, I)$ if $\\beta_t$ is properly chosen.\nTheoretically, the reverse-time process [Pardoux, 1986] is governed by the backward SDE:\n\\begin{equation} \\label{eq:sde_backward} d{\\boldsymbol{y}}_t = \\beta_{T-t}[{\\boldsymbol{y}}_t + 2 \\nabla \\log p_{T-t}({\\boldsymbol{y}}_t)]dt + \\sqrt{2\\beta_{T-t}}d{\\boldsymbol{w}}_t, \\quad 0 \\leq t \u0026lt; T, {\\boldsymbol{y}}_0 \\sim p_T \\tag{2} \\end{equation}\nOr equivalently, the associated probability flow ODE:\n\\begin{equation} \\label{eq:flow_reverse_ode} d{\\boldsymbol{y}}_t = \\beta_{T-t}\\left[{\\boldsymbol{y}}_t+ \\nabla\\log p_{T-t}({\\boldsymbol{y}}_t)\\right]dt, \\quad 0 \\leq t \u0026lt; T, {\\boldsymbol{y}}_0 \\sim p_T. \\tag{5} \\end{equation}\nWe illustrate this idea below: assuming that $p_{\\text{data}}$ is Gaussian (left of the figure), the forward process evolves from left to right. The backward SDE (purple) and the probability flow ODE (black) reverse this evolution, with overlapping Gaussian ellipses in blue at each time step.\nError Types in Diffusion Models We identify four distinct sources of error:\nInitialization error Truncation error Discretization error Score approximation error Initialization Error Occurs when the backward SDE or flow ODE is initialized with $\\mathcal{N}(0,I)$ instead of the true $p_T$. This mismatch arises because $p_T$ is unknown in general. Although the forward process converges to $\\mathcal{N}(0, I$ asymptotically, in practice we must use a finite $T$. This mismatch causes divergence between the SDE and ODE reverse marginals.\nTruncation Error This error results from stopping the reverse process at some small $\\varepsilon \u0026gt; 0$ instead of time 0. It\u0026rsquo;s necessary when the data distribution lacks a density, e.g. if it\u0026rsquo;s supported on a manifold, making $\\nabla \\log p_t$ undefined at $t=0$.\nDiscretization Error Discretizing the backward SDE or flow ODE is required for numerical simulation. The choice of discretization scheme (Euler, Heun, etc.) directly impacts the quality of the generated samples.\nScore Approximation Error In practice, the score function $\\nabla \\log p_t$ is unknown and approximated by a neural network $s_\\theta$. This introduces a model approximation error. The success of diffusion models hinges on the quality of this learned score function.\nAnalysis Under Gaussian Assumption To precisely analyze these errors, we focus on a tractable case:\nAssumption (Gaussian assumption): $\\quad p_{\\text{data}} = \\mathcal{N}(0, \\boldsymbol{\\Sigma}) $\nThis allows closed-form derivations. The covariance matrix $\\boldsymbol{\\Sigma}$ may be non-invertible, in which case the data lies on a manifold.\nThe exact score is given by:\n\\begin{equation} \\nabla_{\\boldsymbol{x}} \\log p_t(\\boldsymbol{x}) = -\\boldsymbol{\\Sigma}_t^{-1} \\boldsymbol{x} \\end{equation}\nwhere $ \\boldsymbol{\\Sigma}_t = e^{-\\int_0^t \\beta_s ds} \\boldsymbol{\\Sigma} + (1 - e^{-\\int_0^t \\beta_s ds}) I $.\nNote: When $\\boldsymbol{\\Sigma} $ is singular, the score is undefined at $t = 0$, explaining the necessity of truncation.\nIn this Gaussian setting, we:\nDerive closed-form solutions for the backward SDE (Proposition 2) Solve the probability flow ODE exactly (Proposition 3) Compute exact Wasserstein-2 errors from initialization, truncation, and discretization (Section 4) Empirically study the score approximation error (Section 5) Key Takeaways With only initialization error, the ODE sampler is more accurate than the SDE sampler (Proposition 4) Adding truncation and discretization errors, Heun\u0026rsquo;s method applied to the ODE yields the best performance (Figure 1) Score approximation is the most critical error in practice, and the SDE sampler is more robust to this noise For full derivations and results, see the paper.\nBibtex @inproceedings{Pierret_Galerne_diffusion_models_Gaussian_exact_solutions_errors_ICML2025, title={Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors}, author={Emile Pierret and Bruno Galerne}, booktitle={Forty-second International Conference on Machine Learning}, year={2025}, } References [Song et al., 2021] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, \u0026 Ben Poole (2021). Score-Based Generative Modeling through Stochastic Differential Equations. In International Conference on Learning Representations. [Pardoux, 1986] Pardoux, Étienne. Grossissement d'une filtration et retournement du temps d'une diffusion. Séminaire de probabilités, Tome 20 (1986), pp. 48-55. ","date":1746057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746057600,"objectID":"827db7e98af52491be5c9ebfddb1ef5f","permalink":"http://localhost:1313/publication/w2_gaussian/","publishdate":"2025-05-01T00:00:00Z","relpermalink":"/publication/w2_gaussian/","section":"publication","summary":"Diffusion or score-based models recently showed high performance in image generation. They rely on a forward and a backward stochastic differential equations (SDE). The sampling of a data distribution is achieved by numerically solving the backward SDE or its associated flow ODE. Studying the convergence of these models necessitates to control four different types of error: the initialization error, the truncation error, the discretization error and the score approximation. In this paper, we theoretically study the behavior of diffusion models and their numerical implementation when the data distribution is Gaussian. Our first contribution is to derive the analytical solutions of the backward SDE and the probability flow ODE and to prove that these solutions and their discretizations are all Gaussian processes. Our second contribution is to compute the exact Wasserstein errors between the target and the numerically sampled distributions for any numerical scheme. This allows us to monitor convergence directly in the data space, while experimental works limit their empirical analysis to Inception features.","tags":["Diffusion models","image generation","differential equations","discretization schemes"],"title":"Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors","type":"publication"},{"authors":["Emile Pierret","Bruno Galerne"],"categories":[],"content":"","date":1744243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744243200,"objectID":"8b3f793f79ea3fb5484fd104c75e7e65","permalink":"http://localhost:1313/publication/gaussian_sr/","publishdate":"2025-04-10T00:00:00Z","relpermalink":"/publication/gaussian_sr/","section":"publication","summary":"Super-Resolution (SR) is the problem that consists in reconstructing images that have been degraded by a zoom-out operator. This is an ill-posed problem that does not have a unique solution, and numerical approaches rely on a prior on high-resolution images. While optimization-based methods are generally deterministic, with the rise of image generative models more and more interest has been given to stochastic SR, that is, sampling among all possible SR images associated with a given low-resolution input. In this paper, we construct an efficient, stable and provably exact sampler for the stochastic SR of Gaussian microtextures. Even though our approach is limited regarding the scope of images it encompasses, our algorithm is competitive with deep learning state-of-the-art methods both in terms of perceptual metric and execution time when applied to microtextures. The framework of Gaussian microtextures also allows us to rigorously discuss the limitations of various reconstruction metrics to evaluate the efficiency of SR routines.","tags":["stochastic super-resolution","Gaussian textures","conditional simulation","kriging","super-resolution with a reference image"],"title":"Stochastic super-resolution for Gaussian microtextures","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6f2ae24689dd626422f36a03d187ca38","permalink":"http://localhost:1313/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/featured/","section":"","summary":"Publications","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8e7bc052bdfc6746ea2bb6595e8093eb","permalink":"http://localhost:1313/home/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"More details on selected publications from this list can be found in the Featured Publications section.\nPreprint Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions Émile Pierret and Bruno Galerne, 2025. Submitted preprint. hal, arXiv Bibtex @misc{Pierret_Galerne_Evaluation_accuracy_diffusion_models, author={Pierret, \\'Emile and Galerne, Bruno}, booktitle={Submitted Preprint}, title={Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions}, year={2025} } Conference publications Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors. Émile Pierret and Bruno Galerne, 2025. Accepted at ICML 2025. hal, arXiv, GitHub Bibtex @inproceedings{Pierret_Galerne_diffusion_models_Gaussian_exact_solutions_errors_ICML2025, title={Diffusion models for Gaussian distributions: Exact solutions and Wasserstein errors}, author={Emile Pierret and Bruno Galerne}, booktitle={Forty-second International Conference on Machine Learning}, year={2025}, } Stochastic Super-Resolution for Gaussian textures. Émile Pierret and Bruno Galerne, 2023. ICASSP 2023. hal, arXiv, IEEE preview Bibtex @inproceedings{Pierret_Galerne_stochastic_SR_for_gaussian_textures_ICASSP_2023, author={Pierret, Émile and Galerne, Bruno}, booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Stochastic Super-Resolution For Gaussian Textures}, year={2023}, volume={}, number={}, pages={1-5}, doi={10.1109/ICASSP49357.2023.10096585}} Journal publication Stochastic Super-Resolution for Gaussian microtextures. Émile Pierret and Bruno Galerne, 2025. SIAM Journal on Imaging Sciences ( SIIMS), Vol. 18, No. 2, pp. 1176\u0026ndash;1207. hal, arXiv, GitHub Bibtex @article{Pierret_Galerne_stochastic_superresolution_gaussian_microtextures_SIIMS_2025, author = {Pierret, \\'{E}mile and Galerne, Bruno}, title = {Stochastic Super-resolution for Gaussian Microtextures}, journal = {SIAM Journal on Imaging Sciences}, volume = {18}, number = {2}, pages = {1176-1207}, year = {2025}, doi = {10.1137/24M1657407}, } ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7698d838139957763b43fede5b33c2ae","permalink":"http://localhost:1313/list_publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/list_publications/","section":"","summary":"More details on selected publications from this list can be found in the Featured Publications section.\nPreprint Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions Émile Pierret and Bruno Galerne, 2025.","tags":null,"title":"","type":"page"}]